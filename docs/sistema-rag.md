# üß† Sistema RAG (Retrieval-Augmented Generation)

## Vis√£o Geral

O sistema RAG permite que o bot WhatsApp acesse e utilize conhecimento espec√≠fico da organiza√ß√£o para fornecer respostas mais precisas e contextualizadas durante as entrevistas.

**Fluxo**: Pergunta ‚Üí Busca Sem√¢ntica ‚Üí Contexto Relevante ‚Üí Resposta com IA

---

## üèóÔ∏è Arquitetura do Sistema

### Componentes Principais

```mermaid
graph TD
    A[Documento Upload] --> B[Extra√ß√£o de Texto]
    B --> C[Chunking]
    C --> D[Embedding Generation]
    D --> E[Vector Storage]
    
    F[Pergunta do Usu√°rio] --> G[Query Embedding]
    G --> H[Similarity Search]
    H --> I[Context Retrieval]
    I --> J[AI Response]
    
    E --> H
```

### Stack Tecnol√≥gico
- **Embeddings**: OpenAI `text-embedding-ada-002`
- **Vector Storage**: Convex com √≠ndices otimizados
- **Text Processing**: Chunking inteligente por contexto
- **Search**: Busca por similaridade de cosseno
- **AI Integration**: GPT-4 com contexto enriquecido

---

## üìÑ Processamento de Documentos

### Formatos Suportados

```typescript
interface SupportedFormats {
  'application/pdf': {
    maxSize: '10MB',
    processor: 'pdf-parse',
    features: ['text', 'metadata']
  },
  'text/plain': {
    maxSize: '5MB',
    processor: 'direct',
    features: ['text']
  },
  'text/markdown': {
    maxSize: '5MB',
    processor: 'markdown-parser',
    features: ['text', 'structure']
  },
  'application/msword': {
    maxSize: '10MB',
    processor: 'mammoth',
    features: ['text', 'formatting']
  }
}
```

### Pipeline de Processamento

#### 1. Upload e Valida√ß√£o
```typescript
// Valida√ß√£o de arquivo
interface DocumentValidation {
  format: boolean,        // Formato suportado?
  size: boolean,         // Tamanho dentro do limite?
  content: boolean,      // Conte√∫do leg√≠vel?
  encoding: boolean      // Encoding v√°lido?
}
```

#### 2. Extra√ß√£o de Texto
```typescript
// Resultado da extra√ß√£o
interface ExtractedContent {
  text: string,           // Texto limpo
  metadata: {
    title?: string,       // T√≠tulo do documento
    author?: string,      // Autor
    pages?: number,       // N√∫mero de p√°ginas
    wordCount: number,    // Contagem de palavras
    language?: string     // Idioma detectado
  },
  structure?: {
    headings: string[],   // Cabe√ßalhos encontrados
    sections: Section[]   // Se√ß√µes estruturadas
  }
}
```

#### 3. Chunking Inteligente
```typescript
interface ChunkingStrategy {
  maxChunkSize: 1000,           // Tokens por chunk
  overlapSize: 200,             // Sobreposi√ß√£o entre chunks
  splitBy: 'sentence' | 'paragraph' | 'section',
  preserveContext: boolean,     // Manter contexto entre chunks
  metadata: {
    source: string,             // Documento origem
    chunkIndex: number,         // Posi√ß√£o no documento
    section?: string,           // Se√ß√£o do documento
    pageNumber?: number         // P√°gina (se aplic√°vel)
  }
}
```

#### 4. Gera√ß√£o de Embeddings
```typescript
// Configura√ß√£o de embeddings
interface EmbeddingConfig {
  model: 'text-embedding-ada-002',
  dimensions: 1536,
  batchSize: 100,              // Chunks por batch
  retryPolicy: {
    maxRetries: 3,
    backoffMs: 1000
  }
}

// Resultado
interface DocumentEmbedding {
  chunkId: string,
  embedding: number[],         // Vetor 1536D
  text: string,               // Texto original
  metadata: ChunkMetadata
}
```

---

## üîç Sistema de Busca

### Busca Sem√¢ntica

#### Processo de Query
```typescript
async function semanticSearch(query: string, limit: number = 5) {
  // 1. Gerar embedding da pergunta
  const queryEmbedding = await openai.embeddings.create({
    model: "text-embedding-ada-002",
    input: query
  });

  // 2. Buscar chunks similares
  const results = await ctx.db.query("documentEmbeddings")
    .withSearchIndex("by_embedding", (q) => 
      q.similar("embedding", queryEmbedding.data[0].embedding, limit)
    )
    .collect();

  // 3. Calcular scores de relev√¢ncia
  return results.map(chunk => ({
    ...chunk,
    relevanceScore: cosineSimilarity(queryEmbedding, chunk.embedding)
  }));
}
```

#### Filtros Avan√ßados
```typescript
interface SearchFilters {
  documentTypes?: string[],    // Filtrar por tipo de documento
  dateRange?: {               // Filtrar por data
    from: Date,
    to: Date
  },
  minRelevance?: number,      // Score m√≠nimo de relev√¢ncia
  sections?: string[],        // Se√ß√µes espec√≠ficas
  authors?: string[]          // Autores espec√≠ficos
}
```

### Ranking e Relev√¢ncia

#### Algoritmo de Score
```typescript
function calculateRelevanceScore(
  semanticScore: number,      // Similaridade de cosseno
  metadata: ChunkMetadata
): number {
  let score = semanticScore;
  
  // Boost para documentos recentes
  const daysSinceUpload = daysBetween(metadata.uploadDate, new Date());
  if (daysSinceUpload < 30) {
    score *= 1.1;
  }
  
  // Boost para se√ß√µes importantes
  if (metadata.section?.includes('introdu√ß√£o') || 
      metadata.section?.includes('resumo')) {
    score *= 1.2;
  }
  
  // Penalidade para chunks muito pequenos
  if (metadata.wordCount < 50) {
    score *= 0.8;
  }
  
  return score;
}
```

---

## ü§ñ Integra√ß√£o com IA

### Context Assembly

#### Prepara√ß√£o do Contexto
```typescript
interface RAGContext {
  query: string,              // Pergunta original
  relevantChunks: Chunk[],    // Chunks mais relevantes
  conversationHistory: Message[], // Hist√≥rico da conversa
  userProfile: {              // Perfil do usu√°rio
    currentStage: string,
    preferences?: string[],
    previousTopics: string[]
  }
}
```

#### Template de Prompt
```typescript
const RAG_PROMPT_TEMPLATE = `
Voc√™ √© um assistente especializado em entrevistas de jornada pessoal.

CONTEXTO RELEVANTE:
${relevantChunks.map(chunk => `
- Fonte: ${chunk.metadata.source}
- Conte√∫do: ${chunk.text}
- Relev√¢ncia: ${chunk.relevanceScore.toFixed(2)}
`).join('\n')}

HIST√ìRICO DA CONVERSA:
${conversationHistory.slice(-5).map(msg => 
  `${msg.direction}: ${msg.content}`
).join('\n')}

ETAPA ATUAL: ${userProfile.currentStage}

PERGUNTA DO USU√ÅRIO: ${query}

INSTRU√á√ïES:
1. Use o contexto relevante para enriquecer sua resposta
2. Mantenha o foco na etapa atual da entrevista
3. Seja emp√°tico e acolhedor
4. Se o contexto n√£o for suficiente, seja honesto sobre limita√ß√µes
5. Sempre cite as fontes quando usar informa√ß√µes espec√≠ficas

RESPOSTA:
`;
```

### Response Enhancement

#### Cita√ß√£o de Fontes
```typescript
interface EnhancedResponse {
  content: string,            // Resposta principal
  sources: {                  // Fontes utilizadas
    documentName: string,
    section?: string,
    relevanceScore: number,
    snippet: string           // Trecho relevante
  }[],
  confidence: number,         // Confian√ßa na resposta (0-1)
  suggestedFollowUp?: string  // Pergunta de acompanhamento
}
```

---

## üìä Monitoramento e Analytics

### M√©tricas de Performance

#### Qualidade da Busca
```typescript
interface SearchMetrics {
  averageRelevanceScore: number,    // Score m√©dio dos resultados
  queryResponseTime: number,        // Tempo de resposta (ms)
  hitRate: number,                 // % de queries com resultados relevantes
  userSatisfaction: number,        // Feedback dos usu√°rios
  topQueries: {                    // Queries mais frequentes
    query: string,
    count: number,
    avgRelevance: number
  }[]
}
```

#### Uso de Documentos
```typescript
interface DocumentUsage {
  documentId: string,
  name: string,
  totalQueries: number,           // Vezes que foi consultado
  avgRelevanceScore: number,      // Relev√¢ncia m√©dia
  lastUsed: Date,                // √öltima consulta
  topSections: {                 // Se√ß√µes mais utilizadas
    section: string,
    usage: number
  }[]
}
```

### Dashboard de RAG

#### M√©tricas em Tempo Real
- **Queries/min**: Volume de consultas
- **Lat√™ncia p95**: Tempo de resposta
- **Cache Hit Rate**: Efici√™ncia do cache
- **Embedding Usage**: Tokens consumidos

#### An√°lise de Conte√∫do
- **Documentos Mais √öteis**: Por score de relev√¢ncia
- **Gaps de Conhecimento**: Queries sem bons resultados
- **T√≥picos Populares**: Assuntos mais consultados
- **Qualidade por Fonte**: Performance por documento

---

## üîß Configura√ß√£o e Otimiza√ß√£o

### Par√¢metros de Busca

```typescript
interface RAGConfig {
  search: {
    maxResults: 5,              // M√°ximo de chunks por query
    minRelevanceScore: 0.7,     // Score m√≠nimo para incluir
    diversityThreshold: 0.8,    // Evitar chunks muito similares
    contextWindow: 4000         // Tokens m√°ximos de contexto
  },
  chunking: {
    maxChunkSize: 1000,         // Tokens por chunk
    overlapSize: 200,           // Sobreposi√ß√£o
    splitStrategy: 'semantic'   // Como dividir o texto
  },
  caching: {
    queryTTL: 3600,            // Cache de queries (segundos)
    embeddingTTL: 86400,       // Cache de embeddings
    maxCacheSize: 1000         // M√°ximo de queries em cache
  }
}
```

### Otimiza√ß√µes de Performance

#### Cache Inteligente
```typescript
// Cache de queries frequentes
interface QueryCache {
  query: string,
  queryHash: string,          // Hash da query
  results: SearchResult[],
  timestamp: Date,
  hitCount: number           // Quantas vezes foi usado
}

// Cache de embeddings
interface EmbeddingCache {
  text: string,
  textHash: string,
  embedding: number[],
  model: string,
  timestamp: Date
}
```

#### √çndices Otimizados
```typescript
// Convex schema para busca eficiente
export default defineSchema({
  documentEmbeddings: defineTable({
    documentId: v.id("documents"),
    chunkIndex: v.number(),
    text: v.string(),
    embedding: v.array(v.number()),
    metadata: v.object({
      source: v.string(),
      section: v.optional(v.string()),
      wordCount: v.number(),
      uploadDate: v.number()
    })
  })
  .searchIndex("by_embedding", {
    searchField: "embedding",
    filterFields: ["documentId", "metadata.source"]
  })
  .index("by_document", ["documentId", "chunkIndex"])
  .index("by_source", ["metadata.source"])
});
```

---

## üö® Troubleshooting

### Problemas Comuns

#### Baixa Qualidade de Resultados
**Sintomas**: Respostas irrelevantes, score baixo
**Solu√ß√µes**:
```typescript
// 1. Ajustar threshold de relev√¢ncia
const config = {
  minRelevanceScore: 0.6  // Reduzir se muito restritivo
};

// 2. Melhorar chunking
const chunkingConfig = {
  strategy: 'semantic',    // Usar divis√£o sem√¢ntica
  preserveContext: true   // Manter contexto
};

// 3. Reprocessar documentos
await reindexDocument(documentId);
```

#### Lentid√£o na Busca
**Sintomas**: Tempo de resposta > 2s
**Solu√ß√µes**:
```typescript
// 1. Otimizar √≠ndices
await ctx.db.query("documentEmbeddings")
  .withSearchIndex("by_embedding_optimized")  // Usar √≠ndice otimizado
  .collect();

// 2. Implementar cache
const cachedResult = await getFromCache(queryHash);
if (cachedResult) return cachedResult;

// 3. Reduzir dimensionalidade (se necess√°rio)
const embedding = await generateEmbedding(text, { dimensions: 768 });
```

#### Documentos N√£o Processam
**Sintomas**: Status "failed" ou "pending"
**Diagn√≥stico**:
```typescript
// Verificar logs de processamento
const failedDocs = await ctx.db.query("documents")
  .filter(q => q.eq(q.field("status"), "failed"))
  .collect();

// Verificar quota da OpenAI
const usage = await openai.usage.get();
console.log('Tokens restantes:', usage.remaining);
```

### Logs Importantes

#### Convex Functions
```typescript
// Em rag.ts
console.log('Processing document:', documentId);
console.log('Chunks generated:', chunks.length);
console.log('Embeddings created:', embeddings.length);
console.log('Average relevance:', avgScore);
```

#### Performance Monitoring
```typescript
// M√©tricas de busca
const searchStart = Date.now();
const results = await semanticSearch(query);
const searchTime = Date.now() - searchStart;

console.log(`Search completed in ${searchTime}ms`);
console.log(`Found ${results.length} relevant chunks`);
console.log(`Top score: ${results[0]?.relevanceScore}`);
```

---

## üéØ Melhores Pr√°ticas

### Prepara√ß√£o de Documentos
1. **Estruture bem**: Use cabe√ßalhos e se√ß√µes claras
2. **Seja espec√≠fico**: Evite informa√ß√µes gen√©ricas demais
3. **Atualize regularmente**: Mantenha conte√∫do relevante
4. **Teste a qualidade**: Fa√ßa perguntas e veja os resultados

### Otimiza√ß√£o de Queries
1. **Use linguagem natural**: O sistema funciona melhor com perguntas completas
2. **Seja espec√≠fico**: Perguntas vagas geram resultados vagos
3. **Contextualize**: Mencione o contexto da pergunta
4. **Itere**: Refine baseado nos resultados

### Monitoramento Cont√≠nuo
1. **Acompanhe m√©tricas**: Score de relev√¢ncia, tempo de resposta
2. **Analise gaps**: Identifique t√≥picos sem boa cobertura
3. **Colete feedback**: Usu√°rios indicam qualidade das respostas
4. **Otimize regularmente**: Ajuste par√¢metros baseado no uso

---

**üí° Dica**: O sistema RAG funciona melhor com documentos bem estruturados e espec√≠ficos do dom√≠nio. Invista tempo na curadoria do conte√∫do para obter melhores resultados!